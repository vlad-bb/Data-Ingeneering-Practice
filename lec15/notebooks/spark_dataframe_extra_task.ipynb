{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-fc5d0391-1c56-4a12-9d48-3eb281459b96;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.4 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.12.262 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      ":: resolution report :: resolve 156ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.12.262 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.4 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-fc5d0391-1c56-4a12-9d48-3eb281459b96\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/4ms)\n",
      "26/01/19 06:00:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"spark://spark-master:7077\").config(\"spark.jars.packages\", \n",
    "                                                                        \"org.apache.hadoop:hadoop-aws:3.3.4\").appName(\"spark-hw\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.5\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "actor_df = spark.read.csv('../data/actor.csv', header=True, inferSchema=True)\n",
    "address_df = spark.read.csv('../data/address.csv', header=True, inferSchema=True)\n",
    "category_df = spark.read.csv('../data/category.csv', header=True, inferSchema=True)\n",
    "city_df = spark.read.csv('../data/city.csv', header=True, inferSchema=True)\n",
    "country_df = spark.read.csv('../data/country.csv', header=True, inferSchema=True)\n",
    "customer_df = spark.read.csv('../data/customer.csv', header=True, inferSchema=True)\n",
    "film_df = spark.read.csv('../data/film.csv', header=True, inferSchema=True)\n",
    "film_actor_df = spark.read.csv('../data/film_actor.csv', header=True, inferSchema=True)\n",
    "film_category_df = spark.read.csv('../data/film_category.csv', header=True, inferSchema=True)\n",
    "inventory_df = spark.read.csv('../data/inventory.csv', header=True, inferSchema=True)\n",
    "language_df = spark.read.csv('../data/language.csv', header=True, inferSchema=True)\n",
    "payment_df = spark.read.csv('../data/payment.csv', header=True, inferSchema=True)\n",
    "rental_df = spark.read.csv('../data/rental.csv', header=True, inferSchema=True)\n",
    "staff_df = spark.read.csv('../data/staff.csv', header=True, inferSchema=True)\n",
    "store_df = spark.read.csv('../data/store.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Домашнє завдання на тему Spark SQL\n",
    "\n",
    "Задачі з домашнього завдання на SQL потрібно розвʼязати за допомогою Spark SQL DataFrame API.\n",
    "\n",
    "- Дампи таблиць знаходяться в папці `data`. Датафрейми таблиць вже створені в клітинці вище.\n",
    "- Можете створювати стільки нових клітинок, скільки вам необхідно.\n",
    "- Розвʼязок кожної задачі має бути відображений в самому файлі (використати метод `.show()`)\n",
    "- код має бути оформлений у відповідності із одним із стилем, показаним лектором на занятті 13.\n",
    "\n",
    "**Увага!**\n",
    "Використовувати мову запитів SQL безпосередньо забороняється, потрібно використовувати виключно DataFrame API!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1.\n",
    "Вивести кількість фільмів в кожній категорії.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|       name|film_count|\n",
      "+-----------+----------+\n",
      "|     Sports|        74|\n",
      "|    Foreign|        73|\n",
      "|     Family|        69|\n",
      "|Documentary|        68|\n",
      "|  Animation|        66|\n",
      "|     Action|        64|\n",
      "|        New|        63|\n",
      "|      Drama|        62|\n",
      "|     Sci-Fi|        61|\n",
      "|      Games|        61|\n",
      "|   Children|        60|\n",
      "|     Comedy|        58|\n",
      "|   Classics|        57|\n",
      "|     Travel|        57|\n",
      "|     Horror|        56|\n",
      "|      Music|        51|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_films_count = (\n",
    "    film_category_df\n",
    "    .join(F.broadcast(category_df.select(\"category_id\", \"name\")), on=\"category_id\", how=\"inner\")\n",
    "    .groupBy(\"category_id\", \"name\")\n",
    "    .agg(F.count(\"film_id\").alias(\"film_count\"))\n",
    "    .orderBy(F.col(\"film_count\").desc())\n",
    "    .drop(\"category_id\")\n",
    ")\n",
    "\n",
    "df_films_count.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2.\n",
    "Вивести 10 акторів, чиї фільми брали на прокат найбільше.\n",
    "Результат відсортувати за спаданням."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+----------+\n",
      "|actor_id|first_name|  last_name|film_count|\n",
      "+--------+----------+-----------+----------+\n",
      "|     107|      GINA|  DEGENERES|       753|\n",
      "|     181|   MATTHEW|     CARREY|       678|\n",
      "|     198|      MARY|     KEITEL|       674|\n",
      "|     144|    ANGELA|WITHERSPOON|       654|\n",
      "|     102|    WALTER|       TORN|       640|\n",
      "|      60|     HENRY|      BERRY|       612|\n",
      "|     150|     JAYNE|      NOLTE|       611|\n",
      "|      37|       VAL|     BOLGER|       605|\n",
      "|      23|    SANDRA|     KILMER|       604|\n",
      "|      90|      SEAN|    GUINESS|       599|\n",
      "+--------+----------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_actors_df = (\n",
    "    rental_df[[\"rental_id\", \"inventory_id\"]]\n",
    "    .join(inventory_df[[\"film_id\", \"inventory_id\"]], on=\"inventory_id\", how=\"inner\")\n",
    "    .join(film_actor_df[[\"film_id\", \"actor_id\"]], on=\"film_id\", how=\"inner\")\n",
    "    .join(F.broadcast(actor_df[[\"actor_id\", \"first_name\", \"last_name\"]]), on=\"actor_id\",  how=\"inner\")\n",
    "    .groupBy(\"actor_id\", \"first_name\", \"last_name\")\n",
    "    .agg(F.count(\"film_id\").alias(\"film_count\"))\n",
    "    .orderBy(F.col(\"film_count\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "\n",
    "top_actors_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "3.\n",
    "Вивести категорія фільмів, на яку було витрачено найбільше грошей\n",
    "в прокаті"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+\n",
      "|  name|total_amount|\n",
      "+------+------------+\n",
      "|Sports|     5314.21|\n",
      "+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_category_df = (\n",
    "    payment_df[[\"rental_id\", \"amount\"]]\n",
    "    .join(rental_df[[\"rental_id\", \"inventory_id\"]], on=\"rental_id\", how=\"inner\")\n",
    "    .join(inventory_df[[\"film_id\", \"inventory_id\"]], on=\"inventory_id\", how=\"inner\")\n",
    "    .join(film_category_df[[\"film_id\", \"category_id\"]], on=\"film_id\", how=\"inner\")\n",
    "    .join(F.broadcast(category_df[[\"category_id\", \"name\"]]), on=\"category_id\",  how=\"inner\")\n",
    "    .groupBy(\"name\")\n",
    "    .agg(F.bround(F.sum(\"amount\"), 2).alias(\"total_amount\"))\n",
    "    .orderBy(F.col(\"total_amount\").desc())\n",
    "    .limit(1)\n",
    ")\n",
    "\n",
    "top_category_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "4.\n",
    "Вивести назви фільмів, яких не має в inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      ALICE FANTASIA|\n",
      "|         APOLLO TEEN|\n",
      "|      ARGONAUTS TOWN|\n",
      "|       ARK RIDGEMONT|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|   BOONDOCK BALLROOM|\n",
      "|       BUTCH PANTHER|\n",
      "|       CATCH AMISTAD|\n",
      "| CHINATOWN GLADIATOR|\n",
      "|      CHOCOLATE DUCK|\n",
      "|COMMANDMENTS EXPRESS|\n",
      "|    CROSSING DIVORCE|\n",
      "|     CROWDS TELEMARK|\n",
      "|    CRYSTAL BREAKING|\n",
      "|          DAZED PUNK|\n",
      "|DELIVERANCE MULHO...|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       FLOATS GARDEN|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|  GLADIATOR WESTWARD|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_films_df = (\n",
    "    film_df.select(\"film_id\", \"title\")\n",
    "    .join(inventory_df.select(\"film_id\"), on=\"film_id\", how=\"left_anti\")\n",
    "    .drop(\"film_id\")\n",
    "    .orderBy(\"title\")\n",
    ")\n",
    "\n",
    "new_films_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "5.\n",
    "Вивести топ 3 актори, які найбільше зʼявлялись в категорії фільмів “Children”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----------+\n",
      "|first_name|last_name|film_count|\n",
      "+----------+---------+----------+\n",
      "|     HELEN|   VOIGHT|         7|\n",
      "|     SUSAN|    DAVIS|         6|\n",
      "|     RALPH|     CRUZ|         5|\n",
      "+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "children_category_df = category_df.filter(\"name == 'Children'\")\n",
    "\n",
    "top_children_actor_df = (\n",
    "    film_actor_df.select(\"actor_id\", \"film_id\")\n",
    "    .join(film_category_df.select(\"film_id\", \"category_id\"), on=\"film_id\")\n",
    "    .join(F.broadcast(children_category_df.select(\"category_id\", \"name\")), on=\"category_id\")\n",
    "    .join(F.broadcast(actor_df.select(\"actor_id\", \"first_name\", \"last_name\")), on=\"actor_id\")\n",
    "    .groupBy(\"first_name\", \"last_name\")\n",
    "    .agg(F.count(\"film_id\").alias(\"film_count\"))\n",
    "    .orderBy(F.col(\"film_count\").desc())\n",
    "    .limit(3)\n",
    ")\n",
    "\n",
    "top_children_actor_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Stop Spark session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
